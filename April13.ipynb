{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1963a7e5-275d-4436-8ecf-0566feb54a3c",
   "metadata": {},
   "source": [
    "## Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ed12d-fe76-4a08-b314-8d10e741a5e7",
   "metadata": {},
   "source": [
    "\n",
    "A random forest regressor is a machine learning model that uses ensemble learning to improve the accuracy of regression models. It works by training a number of decision trees on different bootstrap samples of the training data. The predictions of the decision trees are then combined to produce a final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec560e-ba6f-4732-9c66-8a6192b5c43e",
   "metadata": {},
   "source": [
    "## Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0377ae-80a3-4e3f-9551-0d0c540d395f",
   "metadata": {},
   "source": [
    "\n",
    "Random forest regressor reduces the risk of overfitting in two ways:\n",
    "\n",
    "- By training multiple decision trees on different bootstrap samples: This helps to prevent the decision trees from becoming too complex and from learning the training data too well.\n",
    "- By averaging the predictions of the decision trees: This helps to reduce the variance of the model and makes it more robust to noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9ab3c-f545-4c3c-a45d-e96e585472a5",
   "metadata": {},
   "source": [
    "## Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213861f-a8be-41d2-9a01-307a140737c5",
   "metadata": {},
   "source": [
    "Random forest regressor aggregates the prediction of multuiple decision trees by taking the average of the all base learner's prediction \n",
    "\n",
    "different base learners are trained on different bootstrap samples each base learner gives it own prediction and the the average of all the base learners is considered as final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19890860-b67f-4851-8e99-bd81cae2f8b5",
   "metadata": {},
   "source": [
    "## Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa8089-4868-4c98-afe1-29e0b796dedf",
   "metadata": {},
   "source": [
    "1. n_estimator : number of trees for training \n",
    "2. max_depth : maximum number of levels in a tree (depth of the tree)\n",
    "3. criterian : entropy or gini impurity\n",
    "4. min_samples_leaf : The minimum number of samples required to create a leaf node in the decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756179f-9066-4467-a16e-7992b5ff05d6",
   "metadata": {},
   "source": [
    "## Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5959073-71d3-4b77-9d4f-a298f60e6b5b",
   "metadata": {},
   "source": [
    "The main difference between a random forest regressor and a decision tree regressor is that a random forest regressor is an ensemble model, while a decision tree regressor is a single model.\n",
    "\n",
    "An ensemble model is a model that is made up of multiple models. The predictions of the individual models are then combined to produce a final prediction.\n",
    "\n",
    "A decision tree regressor is a model that makes predictions by creating a tree-like structure of decisions. The tree is created by recursively splitting the data into smaller and smaller groups until each group is homogeneous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57151f27-29f4-470b-b2be-8d9c40caa29c",
   "metadata": {},
   "source": [
    "## Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef464e-687a-4953-8755-e5686907f339",
   "metadata": {},
   "source": [
    "#### Advantages \n",
    "- Less prone to overfitting: Random forest regressors are less prone to overfitting than single decision trees because they are made up of multiple models. Each model is trained on a different subset of the training data, which helps to prevent the models from becoming too complex and from learning the training data too well.\n",
    "- More accurate: Random forest regressors are generally more accurate than single decision trees. This is because they are able to learn more complex patterns in the data due to the ensemble of models.\n",
    "- Robust to noise: Random forest regressors are robust to noise in the data. This is because they are able to average out the noise in the predictions of the individual models.\n",
    "#### Disadvantages:\n",
    "- Computationally expensive: Random forest regressors are more computationally expensive to train than single decision trees. This is because they have to train multiple models.\n",
    "- Not suitable for small datasets: Random forest regressors may not be suitable for small datasets. This is because they require a large number of samples to train the individual models.\n",
    "- Sensitive to hyperparameters: The performance of random forest regressors can be sensitive to the hyperparameters. This means that it is important to tune the hyperparameters carefully to get the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d54533-2518-4dad-a668-4796619d7667",
   "metadata": {},
   "source": [
    "## Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e344d-9c5a-4877-aa1f-01df7e5dcfd5",
   "metadata": {},
   "source": [
    "The output of a Random Forest Regressor is a continuous numerical value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0746f-8d92-4f0d-87cd-cfd0543b1e52",
   "metadata": {},
   "source": [
    "## Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490c28a-0e25-4b12-b2c4-1972d61cbeb5",
   "metadata": {},
   "source": [
    "While the primary purpose of a Random Forest is to perform regression tasks, it can also be adapted for classification tasks. This adaptation is achieved through a modified version called a Random Forest Classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e615f2-dcfd-4c3b-b558-75b36030e595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
