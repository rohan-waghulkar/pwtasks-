{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22719bb5-b70c-449a-b9a9-73869208f494",
   "metadata": {},
   "source": [
    "## Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdc54707-251e-4abe-9294-cbd237a5ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf3e95b0-13ce-4194-93d4-33d6b430524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f25aec1-6374-434c-9a76-a8b287a3069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.data\n",
    "y=dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ea9f96-f402-47d5-b48d-3f614d6e64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69103a72-57e2-4846-9895-2a4bbcb83478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3abc6d-13e5-4e24-b443-eb38e7b9f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f902457-69b7-4fe4-b662-180144b9d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e355e-0da7-4684-b374-84a640f67f0d",
   "metadata": {},
   "source": [
    "Here we are getting 100% accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a45b04-e767-4945-8842-1adde5d5336d",
   "metadata": {},
   "source": [
    "## Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630e933-1470-4f4c-8c43-24c1a32a6124",
   "metadata": {},
   "source": [
    " becouse of the load_boston dataset has been removed from sklearn.dataset i am creating my own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7f9ed0f-ca13-4c8c-b271-687a0109d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_regression\n",
    "X1,y1=make_regression(n_samples=1500,n_features=3,n_informative=2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ee00cbe-da87-4911-9c66-8543e7579e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## segregating train and test data\n",
    "X_train1,X_test1,y_train1,y_test1=train_test_split(X1,y1,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aa56fd9-9fe3-45d2-8cd7-4475940cc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "regressor=KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc5bfc8c-b64d-46f7-b5db-282471427292",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train1,y_train1)\n",
    "y_pred1=regressor.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11406fb2-8365-4e07-8b03-198f25933cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980765871784502\n",
      "53.94732159614251\n",
      "5.240641528552322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "print(r2_score(y_pred1,y_test1))\n",
    "print(mean_squared_error(y_pred1,y_test1))\n",
    "print(mean_absolute_error(y_pred1,y_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d698f-1e5f-4c7c-b666-1f6daf137c50",
   "metadata": {},
   "source": [
    "## Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5996b796-73ed-4ad1-8158-8b70c51ad169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=6;, score=0.913 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=6;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=6;, score=0.955 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=6;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=6;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=8;, score=0.913 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=8;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=8;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=8;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=8;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.913 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.955 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 6}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'n_neighbors':[i for i in range(5,10)]}\n",
    "grid=GridSearchCV(KNeighborsClassifier(),param_grid=params,cv=5,refit=True,verbose=3)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682db76d-658d-41ea-ae7b-4175614972f0",
   "metadata": {},
   "source": [
    "## Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4918a5e9-4237-4a3e-80d3-a7ad4e580d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825192716622365\n",
      "49.2606777273997\n",
      "5.023726111516373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()\n",
    "X_train1_scaled=scalar.fit_transform(X_train1)\n",
    "X_test1_scaled=scalar.transform(X_test1)\n",
    "regressor1=KNeighborsRegressor()\n",
    "regressor1.fit(X_train1_scaled,y_train1)\n",
    "y_pred1=regressor1.predict(X_test1_scaled)\n",
    "print(r2_score(y_pred1,y_test1))\n",
    "print(mean_squared_error(y_pred1,y_test1))\n",
    "print(mean_absolute_error(y_pred1,y_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcff62-994b-45c1-90a7-82d035c030d2",
   "metadata": {},
   "source": [
    "## Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9d56152-bf43-4ed8-8e75-05ad8d151329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0 0]\n",
      " [0 5 0]\n",
      " [0 0 3]]\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset=load_iris()\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset.data,dataset.target,test_size=0.1,random_state=3)\n",
    "KNClassifier=KNeighborsClassifier(weights='distance')\n",
    "KNClassifier.fit(X_train,y_train)\n",
    "y_pred=KNClassifier.predict(X_test)\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23279b1e-5da7-42c1-a4b7-75ef1ec80fd1",
   "metadata": {},
   "source": [
    "## Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "224b395b-9acb-4080-a8f0-a83c7a0dc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_data(X_train,X_test):\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa9d81-5fc2-40a6-9b16-b45f8a1999f5",
   "metadata": {},
   "source": [
    "## Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa740bfb-1a0f-45b0-9deb-e029d2e9fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distance(p1,p2):\n",
    "    x1,y1=p1\n",
    "    x2,y2=p2\n",
    "    \n",
    "    x=x2-x1\n",
    "    y=y2-y1\n",
    "    \n",
    "    dist=np.sqrt((x**2)+(y**2))\n",
    "    return dist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eacbe7d-d994-44ac-abab-cab2f24d4b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance([2,3],[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f814cb-75d2-4b45-a24e-3a6bd01fd97f",
   "metadata": {},
   "source": [
    "## Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f967ab0-e4c6-49fa-9efa-825dca572375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_dist(p1,p2):\n",
    "    x1,y1=p1\n",
    "    x2,y2=p2\n",
    "    \n",
    "    x=abs(x2-x1)\n",
    "    y=abs(y2-y1)\n",
    "    \n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62d5c462-e436-4265-b2d1-e6fe9093ecfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_dist([2,3],[3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349b589-a8b4-4a1b-8f13-71989bdb5f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
