{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f174fc-b13f-4630-ac20-b7a046fcd04c",
   "metadata": {},
   "source": [
    "## Q1. What is Gradient Boosting Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa91f7-7f8f-4ea2-9c27-3f4fb9b8c198",
   "metadata": {},
   "source": [
    "Gradient boosting regression is a machine learning technique that uses an ensemble of weak learners to build a strong predictive model. The weak learners are typically decision trees, and the ensemble is built in a sequential manner.\n",
    "\n",
    "At each step, the gradient boosting algorithm fits a new tree to the residuals of the previous model. The residuals are the errors made by the previous model, and they represent the parts of the data that the model has not yet been able to explain.\n",
    "\n",
    "The new tree is fitted so that it minimizes the sum of the squared residuals. This means that the tree is trying to reduce the errors made by the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45aef9-1635-41a0-a275-5bce8b141e96",
   "metadata": {},
   "source": [
    "## Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a simple regression problem as an example and train the model on a small dataset. Evaluate the model's performance using metrics such as mean squared error and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd50ce82-b880-4e67-86cc-69185c7757ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def gradient_boost(X,y,learning_rate,n_estimator,max_depth=3):\n",
    "    weak_learners=[]\n",
    "    pred=np.mean(y)\n",
    "    for i in range(n_estimator):\n",
    "        weak_learner=DecisionTreeRegressor(max_depth=max_depth)\n",
    "        error=y-pred\n",
    "        weak_learner.fit(X,error)\n",
    "        pred+=learning_rate*weak_learner.predict(X)\n",
    "        weak_learners.append(weak_learner)\n",
    "    return weak_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcf5c34-a9cb-4f18-819a-e7ba29642c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boost_predict(x,weak_learners,learning_rate):\n",
    "    pred=0;\n",
    "    for i in weak_learners:\n",
    "        #error=y-pred\n",
    "        #i.fit(x,error)\n",
    "        pred+=learning_rate*i.predict(x)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b36620-350b-44e7-b481-767fcf7385a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X,y=make_regression(n_samples=400,n_features=3,n_informative=2,random_state=0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ac50e98-6e37-455c-87a6-16b2f264f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl=gradient_boost(X_train,y_train,0.1,100)\n",
    "pred=gradient_boost_predict([[-1.05462846,  0.82024784,  0.46313033]],wl,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed71ec1-130f-456c-ad10-256416bd446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=gradient_boost_predict([[ 0.99711798,  0.03060182, -0.06964158]],wl,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0af02f53-085b-4d3f-be16-abf0240af78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.86556446]), 7.5404127515016794)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e97cb9b-3c94-4dff-9c73-72de59f99c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=gradient_boost_predict(X_test,wl,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ba228-2404-4185-80c2-617b02003f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba27211-b42b-4127-b2ff-555a1274846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "464b10a3-af81-4b36-8999-d151ac9b879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880870667119432\n",
      "8.305201062590452\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,pred))\n",
    "print(mean_squared_error(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6fb5a-586a-42ac-9f61-576688bae58a",
   "metadata": {},
   "source": [
    "## Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to optimise the performance of the model. Use grid search or random search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf14707-6903-4abc-a9a9-3de3314734e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'n_estimators':[100,125,150,175],\n",
    "            'learning_rate':[0.01,0.1,0.2,0.5],\n",
    "            'max_depth':[4,5,6,7]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36683d1-df58-4c06-be0e-41cd7d88a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43dd5004-3bf0-4a52-8a52-498cd9e1ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a1829c4-73eb-4007-b114-1d6f4b419b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(GradientBoostingRegressor(),param_grid=parameters,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14c6d3ff-cc41-4fb4-81ae-0a5522ba5d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 125, 150, 175]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 125, 150, 175]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2, 0.5],\n",
       "                         'max_depth': [4, 5, 6, 7],\n",
       "                         'n_estimators': [100, 125, 150, 175]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73bb0cc5-990e-4aa8-8280-305b883440b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 175}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "427ca017-65d3-4c24-98ef-51e5624f9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c6614e4-f445-4d33-8c96-13d3d40f4605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9909828033602645\n",
      "6.286414042878829\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,pred2))\n",
    "print(mean_squared_error(y_test,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8e940-b28c-40af-8e8d-ac3e0e16c979",
   "metadata": {},
   "source": [
    "## Q4. What is a weak learner in Gradient Boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e2943-e365-4759-ae30-577ae26ccfcd",
   "metadata": {},
   "source": [
    "- weak leaner in gradient boosting is a model that has very low accuracy or better than random guessing.\n",
    "- These weak learners helps to create a strong model by integrating the prediction power of these weak learners.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be9191-4622-469d-8793-4d1cb1afce01",
   "metadata": {},
   "source": [
    "## Q5. What is the intuition behind the Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc98eb7d-776f-49a1-b962-cbc0818ef317",
   "metadata": {},
   "source": [
    "The intuition behind gradient boodting algorithm is to improve pediction of model by adding new models that will learn from the error made by previous models.\n",
    "- The models that learns from the previous models are known as weak learners. these weak learners are trained on the training data and f error made by previous model.\n",
    "- This process is repeated untill we get the satisfied result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd79ad-c30b-41aa-b6cb-6b62b5dc81f5",
   "metadata": {},
   "source": [
    "## Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caac0e1-167b-437c-90f0-588ad883eaf5",
   "metadata": {},
   "source": [
    "1. Initialize the ensemble with a base model, such as a decision tree.\n",
    "2. Calculate the residuals of the base model, which are the errors made by the model on the training data.\n",
    "3. Fit a new weak learner to the residuals.\n",
    "4. Add the new weak learner to the ensemble.\n",
    "5. Repeat steps 2-4 until the desired accuracy is achieved or until a maximum number of weak learners has been built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a7d76-eb3f-4f62-9628-17163b8a9ecf",
   "metadata": {},
   "source": [
    "## Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dc5de-05a9-4529-bfcb-568eca343726",
   "metadata": {},
   "source": [
    "1. Define a loss function. The loss function is a measure of how well the model fits the data. In gradient boosting, the most common loss function is the mean squared error (MSE).\n",
    "2. Initialize the model with a base model, such as a decision tree.\n",
    "3. Calculate the residuals of the base model, which are the errors made by the model on the training data.\n",
    "4. Fit a new weak learner to the residuals. The weak learner is trained to minimize the loss function.\n",
    "5. Add the new weak learner to the model.\n",
    "6. Update the weights of the weak learners. The weights are updated so that the weak learners that make the biggest contributions to reducing the error are given more weight.\n",
    "7. Repeat steps 4-6 until the desired accuracy is achieved or until a maximum number of weak learners has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa292833-d3d5-4660-8fc6-b1f18fa703e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
