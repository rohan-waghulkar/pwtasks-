{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3cbc4e-444f-44e2-9696-9368169037fd",
   "metadata": {},
   "source": [
    "## Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92c70c-dcab-4f92-b91f-e771811ebf2f",
   "metadata": {},
   "source": [
    "Resampling : Bagging creates multiple boostrap samples from the original datasets .it involves randomly selecting data points from the orginal dataset with replacement to create a new sample as a result each sample becomes slightly different from other.\n",
    "\n",
    "In Bagging multiple decision trees are trained on these bootstrap samples. at the time of prediction each tree has its own prediction and it may differ from other tree's predictions the final prediction is average of all tree's predictions in case of regression and in case of classification voting mechanism is used which makes it less overfit model.\n",
    "\n",
    "we can evaluate each tree's performance on its OOB samples, which provides an estimate of the model's generalization error. This helps you monitor and tune the model for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef40967-3fac-48d6-b3f4-7a9eea09d06c",
   "metadata": {},
   "source": [
    "## Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606caa84-3c67-4b01-8ff6-2bb01376fe2e",
   "metadata": {
    "tags": [
     "d"
    ]
   },
   "source": [
    "Advantages of using different types of base learners in  bagging :\n",
    "1. The main advantage of using different base learners in bagging is it introduce some divesity in the ensemble.each base learner has some strengths and weaknesses. combining different base learners can help to reduce bias and improve overall prediction performance.\n",
    "\n",
    "2. Using diverse base learners can help reduce overfitting. If one base learner overfits the training data, the impact of its overfitting on the ensemble's predictions is likely to be reduced when combined with other base learners that do not overfit in the same way.\n",
    "\n",
    "Disadvantages of Using Different Types of Base Learners:\n",
    "1. Complexity: Managing and combining different types of base learners can add complexity to the modeling process. You may need to deal with different hyperparameters, training procedures, and feature preprocessing for each base learner, which can increase the overall complexity of the ensemble.\n",
    "2. Training Time: Different types of base learners may have varying training times. If some base learners are computationally expensive to train, it can increase the time required to build the ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb41f83-f5ca-439e-b994-8e4dce19f758",
   "metadata": {},
   "source": [
    "## Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9168481-c5a0-4966-aab5-c1846a5cdaa7",
   "metadata": {},
   "source": [
    "Bias: A base learner with high bias is more likely to underfit the training data, which can lead to a high bias in the bagged ensemble. A base learner with low bias is more likely to overfit the training data, which can lead to a high variance in the bagged ensemble.\n",
    "\n",
    "Variance: A base learner with high variance is more likely to make different predictions on different bootstrap samples, which can lead to a high variance in the bagged ensemble. A base learner with low variance is more likely to make similar predictions on different bootstrap samples, which can lead to a low variance in the bagged ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f0d42-cb60-4c64-a623-8a1f56961e51",
   "metadata": {},
   "source": [
    "## Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb84b69-9364-4266-9942-6891225c6554",
   "metadata": {},
   "source": [
    "Yes Bagging can be used for both classification as well as regression task.\n",
    "\n",
    "The difference between how they uses bagging is how the preduction of the base learners are combined.\n",
    "\n",
    "In case of Regression the prediction of the base base learners are combined by averaging their prediction and the average is considered as the final prediction.\n",
    "\n",
    "In case of classification the predictions of base learners are combined by using majority voting. whatever class has higher number of  vote s is consider as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91db27e-250d-4125-926d-875ce89c2b4f",
   "metadata": {},
   "source": [
    "## Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f36f8-e104-446d-962e-5675abafb3b6",
   "metadata": {},
   "source": [
    "The ensemble size in bagging is the number of base learners that are used to create the ensemble model. The ensemble size affects the bias-variance tradeoff of the bagged ensemble.\n",
    "\n",
    "A small ensemble size will have low variance but high bias. This is because the base learners in a small ensemble will be more likely to be similar to each other, which can lead to overfitting.\n",
    "\n",
    "A large ensemble size will have high variance but low bias. This is because the base learners in a large ensemble will be more likely to be different from each other, which can lead to underfitting.\n",
    "\n",
    "there is not any perticular number to choose as an ensemble size. the size is depend on factor like size of dataset.\n",
    "\n",
    "it is better to start with small ensemble size and keep increasing until you get the best performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34882fd-efba-46c6-b288-6319f8f56923",
   "metadata": {},
   "source": [
    "## Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa60ff-b194-4421-aed8-cf1cd0f9b0d9",
   "metadata": {},
   "source": [
    "Fraud detection: Bagging can be used to detect fraudulent transactions by training a set of decision trees on bootstrap samples of the training data. The predictions of the decision trees can then be combined using majority voting to identify fraudulent transactions.\n",
    "\n",
    "Medical diagnosis: Bagging can be used to diagnose diseases by training a set of decision trees on bootstrap samples of the training data. \n",
    "\n",
    "Image classification: Bagging can be used to classify images by training a set of decision trees on bootstrap samples of the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11fba7-0617-4d67-9df9-5e6eba161450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
