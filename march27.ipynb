{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c614daa-3246-4023-826d-27fabbe34f7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c9e5a-e48b-4a21-ae85-7e12b8400ea3",
   "metadata": {},
   "source": [
    "- The R-squred is a statastical measure which represents the accuracy of the Linear regression model\n",
    "- It is calculated as :\n",
    "   \n",
    "   R^2=1-(SSR/SST)\n",
    "   \n",
    "   Where:\n",
    "   \n",
    "   SSR: is sum of residuals, which is difference between actual value of dependent variable and predicted value.\n",
    "   \n",
    "   SST: is the total sum of squares, which is the sum of the squared deviations of the observed values of the dependent variable from the mean of the    \n",
    "   dependent variable.\n",
    "- It represent the accuracy of the model in range of 0 to 1 A value of 0 means that the independent variable does not explain any of the variation in the dependent variable. A value of 1 means that the independent variable perfectly explains the variation in the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaef98a-a737-4ac7-b092-99adc1bc28bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303af540-6b14-4910-a5fb-138d4679888b",
   "metadata": {},
   "source": [
    "#### Adjusted R^2=1-((1-R^2)(N-1))/N-P-1\n",
    "\n",
    "- Where \n",
    "    N=Number of data points\n",
    "   \n",
    "   P=Number of independent features\n",
    "   \n",
    "   R^2=R-squared values.\n",
    "\n",
    "- The main difference between R^2 and Adjusted R^2 is R^2 get increased when adding the additional independent feature,while Adjusted R^2 remains consistent or may decrease when additional independent variables are added to the model.\n",
    "\n",
    "- Also the R^2 is Prone to the outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935258e-b257-4d18-af48-78f0718271ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfeb96a-25ce-47e0-9eda-a1bc3837c12a",
   "metadata": {},
   "source": [
    "- Adjusted R^2 is more appropriate when there are different number of indepenedent valriable for compairing model.\n",
    "- adjusted R-squared is more likely to remain constant or decrease when additional independent variables are added to the model.while R-squared is more likely to increase.\n",
    "- adjusted R-squared is also appropriate over R-squared when there are outliers.\n",
    "- When you are concerned about overfitting the data.\n",
    "- When you are comparing models with different sample sizes.\n",
    "- When the independent variables are correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f8601-fd4e-4472-a3ef-ce9418c8049c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01863c36-4189-4a8a-8800-ea889080c732",
   "metadata": {},
   "source": [
    "1. Root Mean Square Error (RMSE):\n",
    "- RMSE is a widely used metric that measures the square root of the average of the squared differences between the predicted and actual values. It is calculated using the following formula:\n",
    "- RMSE = sqrt(1/n * Σ(yᵢ - ȳ)²)\n",
    "\n",
    "2. Mean Squared Error (MSE):\n",
    "- MSE is similar to RMSE, but it does not take the square root. It is calculated using the formula:\n",
    "- MSE = 1/n * Σ(yᵢ - ȳ)²\n",
    "- MSE is the average of the squared differences between the predicted and actual values. Since it is not in the original unit of the target variable, it is harder to interpret compared to RMSE.\n",
    "\n",
    "3. Mean Absolute Error (MAE):\n",
    "- MAE measures the average absolute difference between the predicted and actual values. It is calculated using the formula:\n",
    "- MAE = 1/n * Σ|yᵢ - ȳ|\n",
    "\n",
    "- MAE is less sensitive to outliers compared to RMSE and MSE since it does not involve squaring the errors. Like MSE, MAE is not in the original unit of the target variable, making it less interpretable than RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a153fd0-05d0-4e9e-b2bd-7f0fa7b780a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3120442-7b87-457d-a8fe-eb8b32a90bb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advantages:\n",
    "1. MSE:\n",
    "- IT is Differentiable\n",
    "2. MAE\n",
    "- Not Affected by outliear as much as MSE and RMSE\n",
    "- As we are not squaring the error it is in the same unit \n",
    "3. RMSE\n",
    "- RMSE is also more interpretable than MSE, as it has the same units as the dependent variable.\n",
    "- more sensitive metric than MSE, meaning that it is more likely to detect small changes in the model's accuracy.\n",
    "## Disadvantages:\n",
    "1. MSE:\n",
    "- It is sensitive to outliears\n",
    "- it is not in the same unit of the target variable.\n",
    "2. MAE\n",
    "- it is less likely to detect small changes in the model's accuracy.\n",
    "3. RMSE\n",
    "- Not Robust to outliears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88447dcb-5f7b-4304-a3e2-e76b007ebdf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb45239-2dc8-41f5-941f-60a006839b8e",
   "metadata": {},
   "source": [
    "- Lasso regularization is also known as L1 regularization. it is used in regression analysis to prevent the overfitting.\n",
    "- Minimize: RSS + λ * (sum of the absolute values of the coefficients)\n",
    "#### Difference \n",
    "- The main difference between Lasso and Ridge regularization is Lasso has the ability to shrink coefficients to exactly zero, effectively performing feature selection. means it can eliminate the perticular feature by setting its coefficient to zero if it is not important But Ridge regression can only shrink coefficients close to zero but not exactly to zero.\n",
    "## when to use Lasso regularization\n",
    "- When there are lagre no.of features in dataset and feature selection important then Lasso regularization is important\n",
    "- To Handle multicollinearity more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b5768-8163-47aa-b9da-bbba1f26b22c",
   "metadata": {},
   "source": [
    "## Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a35cb5-32fb-4617-bcff-61f841682b1b",
   "metadata": {},
   "source": [
    "- There are Two techniques to regularize the linear model including Lasso regularization and Ridge regularization, are the effective methods nnto prevent overfitting.\n",
    "- Let's say we have a linear regression model that is trained on a dataset of house prices. The model has 10 features, and the coefficients of the model are all equal to 1. This means that the model is perfectly fitting the training data, but it is likely to overfit the data.\n",
    "- We can regularize the model by adding a penalty to the loss function. For example, we can use L2 regularization with a penalty . This will shrink the coefficients of the model, making the model less complex and more likely to generalize well to new data.\n",
    "- After regularizing the model, the coefficients will no longer be equal to 1. Instead, they will be smaller, which will make the model less complex. The model will still be able to fit the training data well, but it will be less likely to overfit the data.\n",
    "- Ridge regularization is a type of L2 regularization. It is a popular choice for regularizing linear models because it is relatively easy to implement and it can be effective in preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9e0d5-ff1e-4db5-946e-7e0397e999a2",
   "metadata": {},
   "source": [
    "## Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921a8b7-b078-45d6-85e4-219ba53e06c2",
   "metadata": {},
   "source": [
    "- One limitation of regularized linear models is that they can reduce the accuracy of the model. This is because regularization shrinks the coefficients of the model, which can make the model less sensitive to the features in the data. In some cases, this can lead to a decrease in the accuracy of the model.\n",
    "\n",
    "- Another limitation of regularized linear models is that they can be difficult to interpret. This is because regularization can shrink the coefficients of the model to zero, which means that some of the features in the data will not be used by the model. This can make it difficult to understand why the model is making the predictions that it is making.\n",
    "- Becouse of regularization can shrink the coefficients of the model to zero, some of the features in the data will not be used by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e788a43-3a2f-49b0-8edd-191b0c413cc8",
   "metadata": {},
   "source": [
    "## Q9. You are comparing the performance of two regression models using different evaluation metrics. Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d86d81-e24b-44f1-98c8-04d18127d1e0",
   "metadata": {},
   "source": [
    "- In general, a lower RMSE or MAE value indicates a better fit of the model. \n",
    "- In the case of Model A and Model B, Model B has a lower MAE value, which means that it has a lower average error than Model A. This suggests that Model B is a better performer than Model A.\n",
    "- But it is important to rememver that MAE is more sensetive to outliears than RMSE.If no outliear are there in the dataset model B would be the better choice but not in presence of outliers.\n",
    "- Therefore i would go with model A Even its coefficent is higher,it wont get affected by the outliers.\n",
    "- Even RMSE is less affected by the outliers it has some limitations:\n",
    "1. RMSE is not as interpretable as MAE. RMSE is measured in the same units as the dependent variable, which can make it difficult to interpret. MAE is measured in the units of the dependent variable, which makes it easier to interpret.\n",
    "2. MAE is more sensitive to outliers than RMSE. This means that if there are outliers in the data, MAE will be more affected by them than RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ff415-63d3-4f20-8725-65384dca007f",
   "metadata": {},
   "source": [
    "## Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9894572-0e6b-487b-824a-bd44e95a9e78",
   "metadata": {},
   "source": [
    "- In the case of Model A and Model B, Model A uses Ridge regularization with a regularization parameter of 0.1, which is a relatively small value. This means that Model A will not be very strongly regularized, and the coefficients will not be shrunk very much. Model B uses Lasso regularization with a regularization parameter of 0.5, which is a relatively large value. This means that Model B will be strongly regularized, and some of the coefficients may be shrunk to zero.\n",
    "-  If the goal is to prevent overfitting and to obtain a relatively smooth model, then Model A would be a better choice. However, if the goal is to select a subset of the features that are most important for the model, then Model B would be a better choice.\n",
    "- There are some trade-offs and limitations to the choice of regularization method.\n",
    "1. Ridge regularization:\n",
    "- Smoothness: Ridge regularization can produce smoother models than Lasso regularization. This can be beneficial if the goal is to obtain a model that is easy to interpret.\n",
    "- Overfitting: Ridge regularization can be less effective at preventing overfitting than Lasso regularization. This is because Ridge regularization does not shrink the coefficients as much as Lasso regularization.\n",
    "2. Lasso regularization:\n",
    "- Feature selection: Lasso regularization can be used to select a subset of the features that are most important for the model. This can be beneficial if the goal is to reduce the complexity of the model or to improve the interpretability of the model.\n",
    "- Interpretability: Lasso regularization can produce models that are more difficult to interpret than Ridge regularization. This is because Lasso regularization can shrink coefficients to zero, which can make it difficult to understand which features are important for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09b594-6ad9-4602-b7c3-9abe3ab1ba04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
